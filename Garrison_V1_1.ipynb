{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Garrison V1.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6jdVpcD0epl",
        "outputId": "4a594fb4-89a0-445b-e52c-df93e5e8bb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Generate dataset from file\n",
        "df = pd.read_csv ('dataset/corpus.csv', usecols= ['title','description'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   title                                        description\n",
            "0           court agrees to expedite n.f.l.'s appeal\\r\\n  the decision means a ruling could be made near...\n",
            "1      investing: can you profit in agricultural comm...  bad weather is one factor behind soaring food ...\n",
            "2      no tsunami but fifa's corruption storm rages o...  though jack warner's threatened soccer tsunami...\n",
            "3      critic's corner weekend: 'fringe' wraps third ...  joshua jackson's show goes out with a bang. pl...\n",
            "4      f.b.i. seeks help cracking code in victim's no...  the f.b.i. is asking for the public's help in ...\n",
            "...                                                  ...                                                ...\n",
            "32599     new app answers practical, weird questions\\r\\n  need to know how to fend off a mountain lion o...\n",
            "32600  alex burrows readies for final with plenty on ...  alex burrows took a day off from hockey, but n...\n",
            "32601   chip sector bellwether asml to see strong q1\\r\\n  dutch chip equipment maker asml kicks off the ...\n",
            "32602  amazon betting on cloud computing, sacrificing...  amazon.com inc is thinking long-term when it s...\n",
            "32603  twitter says it will stick with san francisco\\r\\n  twitter, after threatening to leave the city b...\n",
            "\n",
            "[32604 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RrdaNEl3f98",
        "outputId": "aca1cb6e-e32a-4b4f-88db-444348fb9d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Fuse the two columns title and description in one new colun called corpus\n",
        "df['corpus'] = df['title'] + df['description']\n",
        "document = df['corpus']\n",
        "print(document)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        court agrees to expedite n.f.l.'s appeal\\r\\nth...\n",
            "1        investing: can you profit in agricultural comm...\n",
            "2        no tsunami but fifa's corruption storm rages o...\n",
            "3        critic's corner weekend: 'fringe' wraps third ...\n",
            "4        f.b.i. seeks help cracking code in victim's no...\n",
            "                               ...                        \n",
            "32599    new app answers practical, weird questions\\r\\n...\n",
            "32600    alex burrows readies for final with plenty on ...\n",
            "32601    chip sector bellwether asml to see strong q1\\r...\n",
            "32602    amazon betting on cloud computing, sacrificing...\n",
            "32603    twitter says it will stick with san francisco\\...\n",
            "Name: corpus, Length: 32604, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pY2gxO8rj0X"
      },
      "source": [
        "# imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-DqR3BrmZ6",
        "outputId": "b32aa822-784f-42a0-9b68-cf5881b032d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Term Frequency - Inverse Document Frequency Matrix \n",
        "# on the document to get most frequents term in the dataset\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(document)\n",
        "\n",
        "# We will now implement our k-means clustering algorithm in our vectorized document\n",
        "true_k = 10\n",
        "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=150, n_init=1)\n",
        "model.fit(X)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=150,\n",
              "       n_clusters=10, n_init=1, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI6Yi7XorrXm",
        "outputId": "b5abd46f-f7bc-4dec-f2e8-15ab64c52a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Get centroids and Features\n",
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1] # divided per cluster, all the indexes ordered by term frequency\n",
        "terms = vectorizer.get_feature_names() # all terms from vectorized space\n",
        "\n",
        "# Now we can print the centroids into which clusters they belongs\n",
        "for i in range(true_k):\n",
        " print(\"Cluster %d:\" % i),\n",
        " for ind in order_centroids[i, :10]:\n",
        "  print(\" %s\" % terms[ind])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster 0:\n",
            " said\n",
            " year\n",
            " state\n",
            " wednesday\n",
            " says\n",
            " tuesday\n",
            " thursday\n",
            " years\n",
            " world\n",
            " day\n",
            "Cluster 1:\n",
            " game\n",
            " nfl\n",
            " win\n",
            " league\n",
            " players\n",
            " season\n",
            " heat\n",
            " mets\n",
            " red\n",
            " yankees\n",
            "Cluster 2:\n",
            " china\n",
            " chinese\n",
            " said\n",
            " artist\n",
            " beijing\n",
            " asia\n",
            " ai\n",
            " inflation\n",
            " rights\n",
            " government\n",
            "Cluster 3:\n",
            " week\n",
            " election\n",
            " ivory\n",
            " coast\n",
            " presidential\n",
            " gbagbo\n",
            " president\n",
            " said\n",
            " peru\n",
            " ouattara\n",
            "Cluster 4:\n",
            " oil\n",
            " prices\n",
            " sales\n",
            " profit\n",
            " percent\n",
            " stocks\n",
            " billion\n",
            " year\n",
            " quarter\n",
            " fed\n",
            "Cluster 5:\n",
            " japan\n",
            " nuclear\n",
            " plant\n",
            " earthquake\n",
            " tsunami\n",
            " crisis\n",
            " power\n",
            " radiation\n",
            " japanese\n",
            " quake\n",
            "Cluster 6:\n",
            " new\n",
            " york\n",
            " study\n",
            " jersey\n",
            " city\n",
            " state\n",
            " said\n",
            " according\n",
            " theater\n",
            " women\n",
            "Cluster 7:\n",
            " laden\n",
            " bin\n",
            " forces\n",
            " killed\n",
            " libyan\n",
            " pakistan\n",
            " nato\n",
            " al\n",
            " libya\n",
            " said\n",
            "Cluster 8:\n",
            " south\n",
            " tornado\n",
            " north\n",
            " river\n",
            " tornadoes\n",
            " sudan\n",
            " mississippi\n",
            " storms\n",
            " korea\n",
            " joplin\n",
            "Cluster 9:\n",
            " open\n",
            " nadal\n",
            " french\n",
            " djokovic\n",
            " canucks\n",
            " federer\n",
            " final\n",
            " masters\n",
            " round\n",
            " vancouver\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07EhN_cFscLI",
        "outputId": "ea79ace0-9d0f-4e7e-933a-7dd424014092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Predict on a custom phrase\n",
        "print(\"\\n\")\n",
        "TEST = pd.read_csv('dataset/test.csv', usecols= ['user','description'])['description']\n",
        "X = vectorizer.transform(TEST)\n",
        "predicteds = model.predict(X)\n",
        "\n",
        "print(\"==========================================================\")\n",
        "print(predicteds)\n",
        "print(\"==========================================================\")\n",
        "\n",
        "# Print results of prediction: topics in the test sentence\n",
        "print(\"Top 3 Predicted topics for:\")\n",
        "print(\"==========================================================\")\n",
        "\n",
        "for i, predicted in enumerate(predicteds):\n",
        "  print(TEST[i])\n",
        "  print(\"============================ : ===========================\")\n",
        "  for j in order_centroids[predicted, :10]:\n",
        "    print(\"%s\" % terms[j])\n",
        "  print(\"==========================================================\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "==========================================================\n",
            "[5 0 0 0 0 0 0]\n",
            "==========================================================\n",
            "Top 3 Predicted topics for:\n",
            "==========================================================\n",
            "A nuclear explosion is an explosion that occurs as a result of the rapid release of energy from a high-speed nuclear reaction. ... It is possible to have an air-burst nuclear explosion without those clouds. Nuclear explosions produce radiation and radioactive debris.\n",
            "============================ : ===========================\n",
            "japan\n",
            "nuclear\n",
            "plant\n",
            "earthquake\n",
            "tsunami\n",
            "crisis\n",
            "power\n",
            "radiation\n",
            "japanese\n",
            "quake\n",
            "==========================================================\n",
            "The absolute number of war deaths has been declining since 1946. In some years in the early post-war era, around half a million people died through direct violence in wars; in contrast, in 2016 the number of all battle-related deaths in conflicts involving at least one state was 87,432.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n",
            "Fantasy is a genre of speculative fiction set in a fictional universe, often inspired by real world myth and folklore. Its roots are in oral traditions, which then became fantasy literature and drama. From the twentieth century it has expanded further into various media, including film, television, graphic novels, manga, animated movies and video games.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n",
            "Serverless is more about the idea of removing the need to worry about the server from the mix of things that is needed to do. It will help if you know about server technology (because sometimes you do), but itâ€™s not a necessity.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n",
            "Improved internet access and more reliable WAN bandwidth have made it easier to push more networking management functions into the cloud. This has been one of the drivers of cloud computing services as well as enterprise cloud software. This, in turn, has spurred demand for cloud networking as well, as customers look for easier ways to access and build networks using cloud-based services.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n",
            "While early cloud adoption was largely about building new applications on Amazon Web Services (AWS), today it is clear that the cloud model is not about just one cloud but the ability to embrace multiple clouds. The continuing investments made by Microsoft Azure, Google Cloud Platform, Oracle Cloud, IBM Cloud, Alibaba Cloud, and VMware provide compelling infrastructure alternatives, each with their own unique value propositions. These cloud providers will continue to build their portfolio of application services over the next decade.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n",
            "Unlike in the past that languished due to developers' inability to pay for expensive, 'packaged' tools, these newer products are available online, often free, open-source, or at low cost, and shared widely across the global developer community.\n",
            "============================ : ===========================\n",
            "said\n",
            "year\n",
            "state\n",
            "wednesday\n",
            "says\n",
            "tuesday\n",
            "thursday\n",
            "years\n",
            "world\n",
            "day\n",
            "==========================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}